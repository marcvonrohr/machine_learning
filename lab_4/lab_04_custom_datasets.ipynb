{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcvonrohr/machine_learning/blob/main/lab_4/lab_04_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vMMBsH5z9Pe"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 1000px\" src=\"https://github.com/HSG-AIML-Teaching/ML2025-Lab/blob/main/lab_4/figures/banner.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8l7yOmRz9Pf"
      },
      "source": [
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/HSG-AIML-Teaching/ML2025-Lab/blob/main/lab_4/figures/hsg_logo.png?raw=1\">\n",
        "\n",
        "##  Lab 04- Custom Datasets in PyTorch\n",
        "\n",
        "Machine Learning, University of St. Gallen, Spring Term 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUsrWLvkz9Pg"
      },
      "source": [
        "\n",
        "In this tutorial, we want to implement a custom PyTorch dataset that processes images of a given dataset folder and prepares inputs for training and evaluation. Although the structure of datasets can significantly for vary, the principles in this tutorial should be applicable to any PyTorch dataset regardless of the folder structure or file formats.\n",
        "\n",
        "Lab Objectives:\n",
        "- Understand dataset structures and how to process dataset files.\n",
        "- Learn how to implement a PyTorch dataset class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZRy5rEvz9Pg"
      },
      "source": [
        "## Example: A Multi-Folder Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co1pf5eBz9Pg"
      },
      "source": [
        "In this example, we have a dataset called **Omniglot** where the images of each class are inside a separate folder. We want to load the images inside each folder which corrsponds to a separate class and return them as instances of that class.\n",
        "\n",
        "First let's download the files that we need from this link: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
        "\n",
        "For more information about the dataset please refer to this link:\n",
        "https://github.com/brendenlake/omniglot/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kio52vxz9Pg"
      },
      "source": [
        "To read the file list from a folder we need a package called `glob`. We use pip to install the package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UeURn049z9Ph",
        "outputId": "9225305e-50d0-4e8c-9423-61d42fef713a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.11/dist-packages (0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install glob2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YbNZLRBLz9Pi",
        "outputId": "9778666c-2f70-44ba-9a4b-f9fb67c77a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 11:15:16--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9464212 (9.0M) [application/zip]\n",
            "Saving to: ‘images_background.zip.5’\n",
            "\n",
            "\rimages_background.z   0%[                    ]       0  --.-KB/s               \rimages_background.z 100%[===================>]   9.03M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-03-24 11:15:16 (123 MB/s) - ‘images_background.zip.5’ saved [9464212/9464212]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p dataset\n",
        "!cd /content/\n",
        "!wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHj1Krcgz9Pi"
      },
      "source": [
        "Now, let's see how we can retrieve and print the list of folders for a given root directory:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Definiere den Pfad zur ZIP-Datei\n",
        "zip_file_path = '/content/images_background.zip'\n",
        "\n",
        "# Definiere den Zielordner für die extrahierten Dateien\n",
        "extract_dir = '/content/dataset'\n",
        "\n",
        "# Erstelle den Zielordner, falls er noch nicht existiert\n",
        "import os\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Entpacke die ZIP-Datei\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f'Die Datei {zip_file_path} wurde erfolgreich in {extract_dir} entpackt.')\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Definiere den Quellordner und den Zielordner\n",
        "source_dir = '/content/dataset/images_background'\n",
        "target_dir = '/content/dataset'\n",
        "\n",
        "# Verschiebe alle Dateien und Ordner\n",
        "for item in os.listdir(source_dir):\n",
        "    source_path = os.path.join(source_dir, item)\n",
        "    target_path = os.path.join(target_dir, item)\n",
        "    shutil.move(source_path, target_path)\n",
        "\n",
        "# Lösche den leeren Quellordner\n",
        "os.rmdir(source_dir)\n",
        "\n",
        "print(f'Alle Dateien und Ordner wurden aus {source_dir} in {target_dir} verschoben und {source_dir} wurde gelöscht.')"
      ],
      "metadata": {
        "id": "I5mm1Zx23E6W",
        "outputId": "486ee53a-0a70-442b-ab2a-2d6a09dacebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Datei /content/images_background.zip wurde erfolgreich in /content/dataset entpackt.\n",
            "Alle Dateien und Ordner wurden aus /content/dataset/images_background in /content/dataset verschoben und /content/dataset/images_background wurde gelöscht.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TehAPMPlz9Pi",
        "outputId": "61b90b75-3275-4d99-fd9a-e4071ecb629b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['character20', 'character07', 'character12', 'character23', 'character18', 'character22', 'character03', 'character15', 'character01', 'character06', 'character11', 'character08', 'character05', 'character21', 'character16', 'character04', 'character17', 'character02', 'character24', 'character10', 'character14', 'character13', 'character19', 'character09']\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "glob.glob(\"dataset/Greek/*\")\n",
        "\n",
        "folder_names = [f.split(\"/\")[-1] for f in glob.glob(\"dataset/Greek/*\")]\n",
        "print(folder_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVWZaq9pz9Pj"
      },
      "source": [
        "If each folder corresponds to a class, we need to map the class name to a class ID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "CC3RZw5Cz9Pj",
        "outputId": "4238315a-9ce7-471d-ac83-184e18fe275f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'character01': 0, 'character02': 1, 'character03': 2, 'character04': 3, 'character05': 4, 'character06': 5, 'character07': 6, 'character08': 7, 'character09': 8, 'character10': 9, 'character11': 10, 'character12': 11, 'character13': 12, 'character14': 13, 'character15': 14, 'character16': 15, 'character17': 16, 'character18': 17, 'character19': 18, 'character20': 19, 'character21': 20, 'character22': 21, 'character23': 22, 'character24': 23}\n"
          ]
        }
      ],
      "source": [
        "name_to_id = {name: id for (id, name) in enumerate(sorted(folder_names))}\n",
        "\n",
        "print(name_to_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr7HPMlhz9Pj"
      },
      "source": [
        "Next, we extract the list of all images in the dataset and assign them their label IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hqlGUXK4z9Pj",
        "outputId": "cc6bec80-3714-4c94-a36c-3ed8ba789f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
          ]
        }
      ],
      "source": [
        "all_files = glob.glob(\"./dataset/Greek/*/*.png\")\n",
        "all_label = [name_to_id[path.split(\"/\")[-2]] for path in all_files]\n",
        "\n",
        "print(all_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoQIpZ26z9Pk"
      },
      "source": [
        "Then, let's define a class that takes care of loading file lists and returning random samples from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "v0opX8pzz9Pk"
      },
      "outputs": [],
      "source": [
        "# CODE TO BE IMPLEMENTED DURING THE TUTORIAL SESSION\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, transform=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        folder_names = [f.split(\"/\")[-1] for f in glob.glob(root + \"/*\")]\n",
        "        name_to_id = {name: id for (id, name) in enumerate(sorted(folder_names))}\n",
        "\n",
        "        self.all_paths = glob.glob(root + \"/*/*.png\")\n",
        "        self.all_label = [name_to_id[path.split(\"/\")[-2]] for path in self.all_paths]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path_i = self.all_paths[index]\n",
        "        image = Image.open(path_i)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.all_label[index]\n",
        "\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt_iEvifz9Pk"
      },
      "source": [
        "Finally, we need to test the implemented PyTorch dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QpPNL6PUz9Pk"
      },
      "outputs": [],
      "source": [
        "my_transform = transforms.ToTensor()\n",
        "my_dataset = MyDataset(root=\"./dataset/Greek\", transform=my_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BvzjhOJtz9Pk",
        "outputId": "44f18bee-c326-4d99-f635-bf8b7a215b4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "len(my_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "W4TmiZFBz9Pl",
        "outputId": "8cfcf82f-a34d-4385-ea7c-dd501266655d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
              " 19)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "my_dataset[13]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtTzQ7ez9Pl"
      },
      "source": [
        "Now, we use the dataset to create a dataloader and iterate through its samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BYeRWZ7Xz9Pl"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "my_dataloder = DataLoader(my_dataset, batch_size=32, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "E2gp8ehDz9Pl",
        "outputId": "11e11443-531f-4f95-b581-078b038c5ad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n",
            "torch.Size([32, 1, 105, 105])\n"
          ]
        }
      ],
      "source": [
        "for batch in my_dataloder:\n",
        "    image, label = batch\n",
        "    print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yeZb8ROz9Pl"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}